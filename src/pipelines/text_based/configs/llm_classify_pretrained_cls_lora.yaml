name: "llm_classify_pretrained_cls_lora"

experiment:
  mode: "pretrained_cls_lora"  # Load continued-pretrained checkpoint, train classifier + LoRA adapters
  notes: >
    Use when you want to continue adapting the LoRA adapters during classifier
    training. Ensure the checkpoint path matches the `final_subdir` saved by
    `llm_pretrain2.py`.

model:
  unsloth_model: "unsloth/Qwen3-8B-Base-unsloth-bnb-4bit"
  pretrained_checkpoint: "/data/scratch/qc25022/gallbladder/experiments/llm_pretrain_Qwen3-8B_test/final_model"
  hidden_size: 4096
  num_labels: 2
  freeze_llm: true          # Keep base model frozen, only LoRA + classifier train
  train_lora: true          # Re-enable LoRA adapter parameters for training

wandb:
  enabled: true
  project: "llm-classification-finetune"

training:
  output_dir: "/data/scratch/qc25022/gallbladder/experiments/llm_classifier_Qwen3-8B_lora"
  overwrite_output_dir: true
  epochs: 20
  batch_size: 8
  eval_batch_size: 12
  learning_rate: 1e-5
  weight_decay: 0.01
  warmup_steps: 100
  gradient_accumulation_steps: 2
  fp16: false
  bf16: true
  logging_steps: 50
  eval_steps: 250
  save_steps: 500
  save_total_limit: 2
  load_in_4bit: true
  multi_label: false

data:
  cutoff_months: 6
  data_dir: "/data/scratch/qc25022/pancreas/tokenised_data_word_level/cprd_upgi/"
  vocab_filepath: "/data/scratch/qc25022/pancreas/tokenised_data_word_level/cprd_upgi/vocab.csv"
  labels_filepath: "/data/scratch/qc25022/upgi/master_subject_labels.csv"
  medical_lookup_filepath: "/data/home/qc25022/CancEHR-Training/src/resources/MedicalDictTranslation2.csv"
  lab_lookup_filepath: "/data/home/qc25022/CancEHR-Training/src/resources/LabLookUP.csv"
  region_lookup_filepath: "/data/home/qc25022/CancEHR-Training/src/resources/RegionLookUp.csv"
  time_lookup_filepath: "/data/home/qc25022/CancEHR-Training/src/resources/TimeLookUp.csv"
  max_length: 2048

